{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pangu mini model demo\n",
    "---\n",
    "``python version = 3.11``\n",
    "\n",
    "> [08/02/2024]: En este notebook se hace intenta probar el modelo [Pangu Weather mini](https://github.com/rudolfmard/Pangu-Weather-mini/tree/main)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# !pip install timm\n",
    "# !pip install pygrib # En linux\n",
    "# !conda install conda-forge::pygrib # En windows use -y flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Importamos paquete local\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer\n",
    "from model import WeatherModel\n",
    "import data_handler as dh\n",
    "import torch\n",
    "from torch.distributed import init_process_group, destroy_process_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint_path=\"checkpoint.pt\" '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esta debe usarse para configurar el uso de GPU\n",
    "\"\"\"\n",
    "if execution_mode == \"single_gpu\":\n",
    "    print(\"Training on single GPU.\")\n",
    "elif execution_mode == \"multi_gpu\":\n",
    "    print(\"Training on multiple GPUs.\")\n",
    "    init_process_group(backend=\"nccl\")\n",
    "else:\n",
    "    raise ValueError(\"Invalid execution mode. Valid values are 'single_gpu' or 'multi_gpu'\")\"\"\"\n",
    "\n",
    "# This environment variable tells PyTorch CUDA allocator not to split memory blocks larger than certain size.\n",
    "# Mitigates GPU memory fragmentation and allows the training of the full original model to fit onto one GPU.\n",
    "\"\"\"os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = 'max_split_size_mb:1024'\"\"\"\n",
    "\n",
    "# Path to checkpoint.pt to continue training from that checkpoint,\n",
    "# if checkpoint.pt does not exist training starts from scratch.\n",
    "\"\"\"checkpoint_path=\"checkpoint.pt\" \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \"\"\"\n",
    "    Training parameters:\n",
    "        learning_rate (float):   Learning rate of the training, 5e-4 in original Pangu-Weather.\n",
    "        max_epochs (int):        Maximum number of epochs for training, 100 in original Pangu-Weather.\n",
    "        save_every (int):        Saves a checkpoint every save_every epoch.\n",
    "        batch_size (int):        Batch size of the training data, 1 in original Pangu-Weather.\n",
    "    \"\"\"\n",
    "    learning_rate = 5e-4\n",
    "    max_epochs = 10\n",
    "    save_every = 2\n",
    "    batch_size = 1\n",
    "\n",
    "    \"\"\"\n",
    "    Model parameters:\n",
    "        C (int):                Dimensionality of patch embedding of the tokens. 192 in original Pangu-Weather. Make sure C is divisible by n_heads.\n",
    "        depth (list[int]):      List with length of 4, defines the number of transformer blocks in each 4 EarthSpecificLayers. [2,6,6,2] in original Pangu-Weather.\n",
    "        n_heads (list[int]):    List with length of 4, defines the number of heads in transformer blocks of each 4 EarthSpecificLayers. [6, 12, 12, 6] in original Pangu-Weather.\n",
    "        D (int):                Dimensionality multiplier of hidden layer in transformer MLP. 4 in original Pangu-Weather.\n",
    "    \"\"\"\n",
    "    C = 192\n",
    "    depth = [2, 6, 6, 2]\n",
    "    n_heads = [6, 12, 12, 6]\n",
    "    D = 4\n",
    "\n",
    "    # Create a model object:\n",
    "    model = WeatherModel(C, depth, n_heads, D, batch_size, log_GPU_mem=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Create dataloader objects for training and validation data:\n",
    "    train_dataset = dh.WeatherDataset(lead_time=1, air_data_path=\"../weather_data/air_test.pt\", surface_data_path=\"../weather_data/surface_test.pt\")\n",
    "    train_dataloader = dh.prepare_dataloader(train_dataset, batch_size, execution_mode)\n",
    "\n",
    "    # If validation_dataloader is set to None, no validation is performed between epochs.\n",
    "    validation_dataset = dh.WeatherDataset(lead_time=1, air_data_path=\"../weather_data/air_test_validation.pt\", surface_data_path=\"../weather_data/surface_test_validation.pt\")\n",
    "    validation_dataloader = dh.prepare_dataloader(validation_dataset, batch_size, execution_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Create loss loss function and optimizer objects:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=3e-6)\n",
    "    loss_fn = torch.nn.L1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Create a trainer object and train the model:\n",
    "    trainer = Trainer(model, train_dataloader, validation_dataloader, loss_fn, optimizer, max_epochs, save_every, execution_mode, checkpoint_path)\n",
    "    trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Calculate RMSE on a batch of data:\n",
    "    calculate_RMSE = True\n",
    "    if calculate_RMSE:\n",
    "        with torch.no_grad(): \n",
    "            device = next(model.parameters()).device\n",
    "            model.eval()\n",
    "\n",
    "            # Fetch a batch from validation dataloader:\n",
    "            data, targets = next(iter(validation_dataloader))\n",
    "\n",
    "            # Move the data to the same device as the model:\n",
    "            data_air, data_surface = data\n",
    "            data_air = data_air.to(device)\n",
    "            data_surface = data_surface.to(device)\n",
    "\n",
    "            targets_air, targets_surface = targets\n",
    "            targets_air = targets_air.to(device)\n",
    "            targets_surface = targets_surface.to(device)\n",
    "\n",
    "            # Make prediction with the model:\n",
    "            output_air, output_surface = model((data_air, data_surface))\n",
    "\n",
    "            # Calculate RMSE of the predictions on unnormalized data:\n",
    "            rmse_values = dh.RMSE((dh.unnormalize_data(output_air), dh.unnormalize_data(output_surface)), \n",
    "                                (dh.unnormalize_data(targets_air), dh.unnormalize_data(targets_surface)), save=True)\n",
    "\n",
    "    if execution_mode == \"multi_gpu\":\n",
    "        destroy_process_group()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "art1_pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
